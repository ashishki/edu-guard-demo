# ğŸ›¡ï¸ Edu-Guard Demo

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)
[![Poetry](https://img.shields.io/badge/Poetry-Managed-orange.svg)](https://python-poetry.org)

> **A sophisticated RAG (Retrieval-Augmented Generation) service with built-in content moderation and multi-LLM support**

## ğŸ¯ Overview

Edu-Guard Demo is a production-ready Python service that demonstrates advanced AI safety patterns by combining:

- **ğŸ” Semantic Search**: Intelligent document retrieval using LlamaIndex + ChromaDB
- **ğŸ›¡ï¸ Content Moderation**: OpenAI-powered guardrails for safe AI interactions  
- **ğŸ¤– Multi-LLM Support**: Parallel querying of OpenAI GPT-3.5 and TogetherAI Mixtral
- **ğŸ—ï¸ Enterprise Architecture**: Clean OOP design with comprehensive testing

### âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| **Semantic Indexing** | Builds vector embeddings from `.txt` files for intelligent context retrieval |
| **Content Moderation** | Blocks harmful prompts using OpenAI Moderation API |
| **Parallel LLM Queries** | Simultaneous requests to multiple AI models for diverse responses |
| **Persistent Storage** | ChromaDB maintains your index across restarts |
| **RESTful API** | Clean FastAPI endpoints with automatic documentation |
| **Test Coverage** | Comprehensive pytest suite for reliability |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚    â”‚   EduChain       â”‚    â”‚  DocumentIndexerâ”‚
â”‚   /ask endpoint â”‚â”€â”€â”€â–¶â”‚   Pipeline       â”‚â”€â”€â”€â–¶â”‚  LlamaIndex +   â”‚
â”‚   Pydantic      â”‚    â”‚   Orchestrator   â”‚    â”‚  ChromaDB       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Guardrails     â”‚
                       â”‚   OpenAI Mod API â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   LLM Clients    â”‚
                       â”‚   OpenAI + Togetherâ”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ Project Structure

```
edu-guard-demo/
â”œâ”€â”€ ğŸ“ app/
â”‚   â”œâ”€â”€ ğŸ›¡ï¸ guardrails.py      # Content moderation logic
â”‚   â”œâ”€â”€ ğŸ¤– llm_client.py      # Multi-LLM wrapper
â”‚   â”œâ”€â”€ ğŸ“š vector_index.py    # Document indexing
â”‚   â”œâ”€â”€ âš™ï¸ educhain.py        # Core pipeline
â”‚   â””â”€â”€ ğŸš€ main.py           # FastAPI application
â”œâ”€â”€ ğŸ“ data/                  # Your .txt documents
â”œâ”€â”€ ğŸ“ chroma_db/            # Persistent vector store
â”œâ”€â”€ ğŸ“ tests/                # Unit test suite
â”œâ”€â”€ ğŸ³ Dockerfile            # Container definition
â”œâ”€â”€ ğŸ³ docker-compose.yml    # Orchestration config
â”œâ”€â”€ ğŸ“ pyproject.toml        # Poetry dependencies
â””â”€â”€ ğŸ”’ .env                  # API keys (create this)
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.12+**
- **Poetry** (for dependency management)
- **Docker & Docker Compose** (optional)
- **OpenAI API Key** (required)
- **TogetherAI API Key** (optional)

### ğŸ”§ Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/ashishki/edu-guard-demo.git
   cd edu-guard-demo
   ```

2. **Configure environment**
   
   Create a `.env` file in the project root:
   ```env
   OPENAI_API_KEY=sk-your-openai-key-here
   # TOGETHER_API_KEY=your-together-key-here  # Optional
   ```

3. **Install dependencies**
   ```bash
   poetry install
   poetry shell
   ```

4. **Run tests**
   ```bash
   pytest
   ```

5. **Start the service**
   ```bash
   uvicorn app.main:app --reload
   ```

### ğŸ¯ Usage

#### Interactive API Documentation
Visit `http://127.0.0.1:8000/docs` for the auto-generated Swagger UI.

#### Example API Calls

**âœ… Safe Query**
```bash
curl -X POST http://127.0.0.1:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"prompt": "What is Python programming?"}'
```

**Response:**
```json
{
  "context": "Python is a high-level programming language...",
  "answers": {
    "openai": "Python is a versatile, high-level programming language..."
  }
}
```

**ğŸš« Blocked Query**
```bash
curl -X POST http://127.0.0.1:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"prompt": "How to harm someone"}'
```

**Response:**
```json
{
  "detail": "Blocked by guardrails: violence"
}
```

---

## ğŸ³ Docker Deployment

### Quick Deploy
```bash
# Build and start services
docker-compose up --build

# Access at http://localhost:8000
```

### Production Deployment
```bash
# Run in detached mode
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

---

## ğŸ§ª Testing

Our comprehensive test suite covers all major components:

### Test Categories

| Test File | Coverage |
|-----------|----------|
| `test_vector_index.py` | Document indexing and retrieval |
| `test_guardrails.py` | Content moderation logic |

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app

# Run specific test file
pytest tests/test_vector_index.py -v
```

---

## ğŸ”§ Configuration

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `OPENAI_API_KEY` | âœ… Yes | OpenAI API key for GPT models |
| `TOGETHER_API_KEY` | âŒ Optional | TogetherAI key for Mixtral model |

### Customization Options

- **Document Sources**: Place your `.txt` files in the `data/` directory
- **Vector Store**: ChromaDB persists in `chroma_db/` directory
- **LLM Models**: Easily add new providers in `llm_client.py`
- **Moderation Rules**: Customize guardrails in `guardrails.py`

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

<details>
<summary><strong>ğŸ”‘ "No API key found for OpenAI"</strong></summary>

**Cause**: Missing or incorrectly loaded environment variables.

**Solution**: 
- Ensure `.env` file exists in project root
- Verify `OPENAI_API_KEY` is set correctly
- Check that `load_dotenv()` is called in `app/main.py`
</details>

<details>
<summary><strong>ğŸ”„ "Invalid input type" errors</strong></summary>

**Cause**: Passing dict instead of string to LLM client.

**Solution**: 
- Ensure `LangChainLLMClient` receives string prompts
- Check that response extraction uses `.content` or `.text`
</details>

<details>
<summary><strong>ğŸ“Š "Number of requested results greater than elements"</strong></summary>

**Cause**: Vector index has fewer chunks than requested.

**Solution**: 
- This is just a warning, not an error
- The system automatically adjusts to available chunks
</details>

<details>
<summary><strong>ğŸš« Unexpected moderation blocks</strong></summary>

**Cause**: OpenAI Moderation API flagged benign content.

**Solution**: 
- Rephrase your prompt
- Review moderation thresholds in `guardrails.py`
- Use test mocks for development
</details>

---

## ğŸš€ Future Enhancements

### Planned Features

- [ ] **Advanced Guardrails**: Integration with Guardrails-AI library
- [ ] **Web Interface**: React/Vue frontend for interactive queries  
- [ ] **Metrics Dashboard**: Request/response analytics and monitoring
- [ ] **Caching Layer**: Redis-based response caching
- [ ] **Multi-format Support**: PDF, DOCX, and markdown document indexing
- [ ] **Fine-tuning Pipeline**: Custom model training workflows

### Extension Ideas

- **Multi-tenant Support**: Isolated indexes per user/organization
- **Streaming Responses**: Real-time answer generation
- **Advanced RAG**: Hybrid search combining semantic and keyword matching
- **Model Comparison**: Side-by-side LLM response analysis

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **LlamaIndex** for powerful document indexing capabilities
- **FastAPI** for the excellent web framework
- **ChromaDB** for efficient vector storage
- **OpenAI** for moderation and language model APIs
- **TogetherAI** for additional LLM options

---

<div align="center">

**â­ If you find this project helpful, please give it a star! â­**

[![GitHub Stars](https://img.shields.io/github/stars/ashishki/edu-guard-demo?style=social)](https://github.com/ashishki/edu-guard-demo)

</div>